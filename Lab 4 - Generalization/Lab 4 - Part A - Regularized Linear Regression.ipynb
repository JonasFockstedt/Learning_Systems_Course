{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 (Part A): Regularized Linear Regression\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "__IMPORTANT__ \n",
    "Please complete this Jupyter Notebook file and upload it to blackboard __before 20 February 2020__.\n",
    "</div>\n",
    "\n",
    "In this Lab, you will implement regularized linear regression and use it to study models with different bias-variance properties. Before starting, we strongly recommend reading the slides of lectures 4.1 and 4.2.\n",
    "\n",
    "In this part of the Lab, you will first implement regularized linear regression to predict the amount of water owing out of a dam using the change of water level in a reservoir. Then, you will examine the effects of bias vs. variance.\n",
    "\n",
    "## Loading the data\n",
    "We have a file `water-level-dataset.mat` which contains the dataset for our linear regression problem. The `.mat` file can be loaded in Python using `scipy.io.loadmat(..)` which returns a dictionary that contains 6 arrays. The follwing Python code load these arrays into the variables: `X`, `y`, `Xtest`, `ytest`, `Xval`, `yval`. So, our data is divided into three parts:\n",
    "- A training set that your model will learn on: `X`, `y`\n",
    "- A cross validation set for determining the regularization parameter: `Xval`, `yval`\n",
    "- A test set for evaluating performance. These are *unseen* examples which your model did not see during training: `Xtest`, `ytest`.\n",
    "\n",
    "Read the following code and print a small subset of these arrays to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-15.93675813]\n",
      " [-29.15297922]\n",
      " [ 36.18954863]\n",
      " [ 37.49218733]\n",
      " [-48.05882945]\n",
      " [ -8.94145794]\n",
      " [ 15.30779289]\n",
      " [-34.70626581]\n",
      " [  1.38915437]\n",
      " [-44.38375985]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from scipy.io import loadmat\n",
    "\n",
    "mat = loadmat(\"datasets/water-level-dataset.mat\")\n",
    "\n",
    "# X and y correspond to a training set that your model will learn on.\n",
    "X = mat[\"X\"]\n",
    "y = mat[\"y\"].reshape(len(X))\n",
    "\n",
    "# Xval and yval correspond to a cross validation set for determining the regularization parameter.\n",
    "Xval = mat[\"Xval\"]\n",
    "yval = mat[\"yval\"].reshape(len(Xval))\n",
    "\n",
    "# Xtest and ytest correspond to a test set for evaluating performance. These \n",
    "# are unseen examples which your model will not see during training\n",
    "Xtest = mat[\"Xtest\"]\n",
    "ytest = mat[\"ytest\"].reshape(len(Xtest))\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "You can print here a small subset of X, y, Xtest, ytest, Xval and Xval to see what they look like.\n",
    "\"\"\"\n",
    "print(X[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "We will begin by visualizing the dataset containing historical records on the change in the water level, $x$, and the amount of water owing out of the dam, $y$. Note that the input data $X$ consists of only one feature corresponding to the \"change in water level\". Produce a scatter plot showing this feature vs. the output corresponding to the \"water flowing out of the dam\". Your plot should look like the following figure:\n",
    "<img src=\"imgs/WaterDataScatterLab4A.png\" width=\"400px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.85\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "\"\"\" TODO:\n",
    "Using the training dataset X and y, produce a scatter plot showing the \"change in water level\" on \n",
    "the x-axis and the \"water flowing out of the dam\" on the y-axis, as shown in the previous figure.\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, y, marker=\"x\", color=\"red\")\n",
    "ax.set_ylabel(\"Water flowing out of the dam(y)\")\n",
    "ax.set_xlabel(\"Change in water level(x)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a first column of ones to the dataset\n",
    "As usual, before starting the implementation of our linear regression model, it might be helpful to use a modified version of our dataset which has an additional first column of ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new: \n",
      "[[  1.         -15.93675813]\n",
      " [  1.         -29.15297922]\n",
      " [  1.          36.18954863]\n",
      " [  1.          37.49218733]\n",
      " [  1.         -48.05882945]\n",
      " [  1.          -8.94145794]\n",
      " [  1.          15.30779289]\n",
      " [  1.         -34.70626581]\n",
      " [  1.           1.38915437]\n",
      " [  1.         -44.38375985]]\n",
      "Xval_new: \n",
      "[[  1.         -16.74653578]\n",
      " [  1.         -14.57747075]\n",
      " [  1.          34.51575866]\n",
      " [  1.         -47.01007574]\n",
      " [  1.          36.97511905]\n",
      " [  1.         -40.68611002]\n",
      " [  1.          -4.47201098]\n",
      " [  1.          26.53363489]\n",
      " [  1.         -42.7976831 ]\n",
      " [  1.          25.37409938]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This function takes a matrix as argument and returns a new matrix with an additional first column (of ones)\n",
    "def add_all_ones_column(X):\n",
    "    n, d = X.shape # dimension of the matrix X (n lines, d columns)\n",
    "    XX = np.ones((n, d+1)) # new matrix of all ones with one additional column\n",
    "    XX[:, 1:] = X # set X starting from column 1 (keep only column 0 unchanged)\n",
    "    return XX\n",
    "\n",
    "# The following line creates a new data matrix X_new with an additional first column (of ones)\n",
    "X_new = add_all_ones_column(X) # for the training set\n",
    "Xval_new = add_all_ones_column(Xval) # for the validation set\n",
    "\n",
    "\"\"\" TODO:\n",
    "You can print a small subset of X_new here to see how it looks like \n",
    "\"\"\"\n",
    "print(f'X_new: \\n{X_new[:10]}')\n",
    "print(f'Xval_new: \\n{Xval_new[:10]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized linear regression cost function\n",
    "Recall that regularized linear regression has the following cost function:\n",
    "$$E(\\theta) = \\frac{1}{2n} \\left ( \\sum_{i=1}^{n} ( h_\\theta(x^{(i)}) - y^{(i)} )^2 \\right ) + \\frac{\\lambda}{2n} \\left ( \\sum_{j=1}^{n} \\theta_j^2 \\right ),$$\n",
    "where $\\lambda$ is a regularization parameter which controls the degree of regularization (thus, help preventing overfitting). The regularization term puts a penalty on the overal cost function $E$. As the magnitudes of the model parameters $\\theta_j$ increase, the penalty increases as well. Note that you should not regularize the $\\theta_0$ term.\n",
    "\n",
    "Complete the following code to write a function to calculate the regularized linear regression cost function. If possible, try to vectorize your code and avoid writing loops. When you are finished, call your cost function using $\\theta$ initialized at `np.array([1, 1])` and $\\lambda = 1$. You should then expect to see an output of about $303.993$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.0348588869309\n"
     ]
    }
   ],
   "source": [
    "\"\"\" TODO:\n",
    "Write the definition of the regularized linear regression cost function. \n",
    "If possible, try to vectorize your code and avoid writing loops. The \n",
    "last argument lmd corresponds to the regularization term lambda.\n",
    "\"\"\"\n",
    "def E(theta, X, y, lmd):\n",
    "    return np.sum((1/(2*n))*np.sum(((h(theta,X)-y)**2))+(lmd/(2*n)*np.sum(theta**2)))\n",
    "\n",
    "def h(theta, X):\n",
    "    return X @ theta\n",
    "\n",
    "\"\"\" TODO:\n",
    "Call your cost function with theta initialized to an array of ones, and \n",
    "lambda = 1. You should expect to see an output of about 303.993.\n",
    "\"\"\"\n",
    "n = len(X)\n",
    "theta = np.array([1, 1])\n",
    "lmd = 1\n",
    "\n",
    "print( E(theta, X_new, y, lmd) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized linear regression gradient\n",
    "The partial derivative of regularized linear regression's cost for $\\theta_j$ is defined as:\n",
    "$$\n",
    "\\frac{\\partial E(\\theta)}{\\partial \\theta_0} = \\frac{1}{n} \\sum_{i=1}^{n} ( h_\\theta(x^{(i)}) - y^{(i)} ) ~ x_j^{(i)}\n",
    "\\quad \\quad \\quad \\quad \\quad \\quad \\text{for } j = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E(\\theta)}{\\partial \\theta_j} = \\left ( \\frac{1}{n} \\sum_{i=1}^{n} ( h_\\theta(x^{(i)}) - y^{(i)} ) ~ x_j^{(i)} \\right ) + \\frac{\\lambda}{n} \\theta_j\n",
    "\\quad \\quad \\text{for } j \\geq 1\n",
    "$$\n",
    "\n",
    "Complete the definition of the function `gradE(..)` in the code below, to calculate the gradient of the cost function $\\nabla E(\\theta)$. The function must return an array of the same length as $\\theta$. When you are finished, call your gradient function using $\\theta$ initialized at `np.array([1, 1])` and $\\lambda = 1$. You should then expect to see a gradient of `[-15.30, 598.250]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO:\n",
    "Write the definition of the gradient function. It should return an array containing \n",
    "the derivative of the cost function with respect to each parameter theta[j].\n",
    "\"\"\"\n",
    "def gradE(theta, X, y, lmd):\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Call your gradient function with theta initialized to an array of ones, and \n",
    "lambda = 1. You should expect to see a gradient of approximatly [-15.30  598.250].\n",
    "\"\"\"\n",
    "# ...\n",
    "# print( gradE(theta, X_new, y, lmd) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting linear regression\n",
    "Once your cost function and gradient are working correctly, the following code will help you to compute the optimal values of $\\theta$. We use `scipy.optimize.minimize(..)` to optimize the cost function.\n",
    "\n",
    "In this part, we set the regularization parameter $\\lambda$ to zero. Because our current implementation of linear regression is trying to fit a 2-dimensional $\\theta$, regularization will not be incredibly helpful for a $\\theta$ of such low dimension. In the later sections of this Lab, you will be using polynomial regression with regularization.\n",
    "\n",
    "For more information about `scipy.optimize.minimize(..)`, you can visit:\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\n",
    "- https://docs.scipy.org/doc/scipy/reference/optimize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as op\n",
    "\n",
    "theta = np.array([0, 0])  # Some initial parameters vector\n",
    "lmd = 0 # We set lambda to zero this time.\n",
    "print(\"Initial cost: \", E(theta, X_new, y, lmd))\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Use op.minimize(..) to minimize the cost function E. Then, print the \n",
    "optimal parameter vector theta and the final cost.\n",
    "\"\"\"\n",
    "# res = op.minimize(......)\n",
    "# Then, the optimal parameters can be accessed with: theta = res.x\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the linear regression model\n",
    "One you get the optimal parameters of $\\theta$, you can call the function `plot_linear_fit(X, y, theta)` defined in the code below to plot the original dataset and the best fit line. Read the code carefully to see how such a line is ploted using the $\\theta$ values. You will get a plot similar to the follwing figure.\n",
    "\n",
    "The best fit line tells us that the model is not a good fit to the data because the data has a non-linear pattern. While visualizing the best fit as shown is one possible way to debug your learning algorithm, it is not always easy to visualize the data and model. In the next section, you will implement a function to generate learning curves that can help you debug your learning algorithm even if it is not easy to visualize the data.\n",
    "\n",
    "<img src=\"imgs/RegLinePlotLab4A.png\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function that plots the original dataset (X, y) and the best fit line:\n",
    "def plot_linear_fit(X, y, theta):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Plottin the training data:\n",
    "    ax.scatter(X[:, 0], y, marker=\"x\", color=\"red\")\n",
    "    ax.set_xlabel(\"Change in water level (x)\")\n",
    "    ax.set_ylabel(\"Water flowing out of the dam (y)\")\n",
    "    \n",
    "    # Plotting the line:\n",
    "    x_min, x_max = np.min(X[:, 0]), np.max(X[:, 0])\n",
    "    plot_x = np.arange(x_min, x_max) # range of values for the x axis\n",
    "    plot_y = theta[0] + theta[1] * plot_x\n",
    "    ax.plot(plot_x, plot_y, color=\"green\", label=\"Best fit line\")\n",
    "    \n",
    "    ax.set_title(\"Plot of the training data and best fit line\")\n",
    "    plt.legend()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Call the function plot_linear_fit(X, y, theta) with \n",
    "the optimal theta parameters that you got previously.\n",
    "\"\"\"\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-variance\n",
    "An important concept in machine learning is the bias-variance tradeoff. Models with high bias are not complex enough for the data and tend to underfit, while models with high variance overfit to the training data. In this part of the Lab, you will plot training and test errors on a learning curve to diagnose bias-variance problems.\n",
    "\n",
    "You will now implement code to generate the learning curves that will be useful in debugging learning algorithms. Recall that a learning curve plots training and cross validation error as a function of training set size. Your job is to fill in the code below so that it returns a vector of errors for the training set and cross validation set.\n",
    "\n",
    "To plot the learning curve, we need a training and cross validation set error for different training set sizes. To obtain different training set sizes, you should use different subsets of the original training set $X$. Specifically, for a training set size of $i$, you should use the first $i$ examples (i.e., `X[1:i]` and `y[1:i]`).\n",
    "\n",
    "You can use the `scipy.optimize.minimize(..)` function to find the $\\theta$ parameters. After learning the $\\theta$ parameters, you should compute the error on the training and cross validation sets. Recall that the training error for a dataset is defined as:\n",
    "\n",
    "$$E(\\theta) = \\frac{1}{2n} \\sum_{i=1}^{n} ( h_\\theta(x^{(i)}) - y^{(i)} )^2$$\n",
    "\n",
    "In particular, note that the training error does not include the regularization term. One way to compute the training error is to use your existing cost function `E(..)` and set $\\lambda$ to $0$ only when using it to compute the training error and cross validation error. When you are computing the training set error, make sure you compute it on the training subset (i.e., `X[0:i]` and `y[0:i]`) (instead of the entire training set). However, for the cross validation error, you should compute it over the entire cross validation set. You should store the computed errors in the vectors error train and error val.\n",
    "\n",
    "When you are finished, print the learning curves and produce a plot similar to the following figure. From the figure, you can observe that both the train error and cross validation error are quite high even when the number of training examples is increased. This reflects a **high bias** problem in the model - the linear regression model is too simple and is unable to fit our dataset well. In the next section, you will implement polynomial regression to fit a better model for this dataset.\n",
    "\n",
    "<img src=\"imgs/LearningCurvLab4A.png\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes some training data, an initial theta and a regularization term \n",
    "# lmd, and returns the optimal prameters vector theta of a linear regression. It uses \n",
    "# scipy.optimize.minimize(..), the cost function E(..) and the gradient gradE(..)\n",
    "def trainLinearReg(X, y, theta_init, lmd):\n",
    "    res = op.minimize(E, theta_init, (X, y, lmd), 'TNC', gradE)\n",
    "    return res.x # the best/final parameters vector theta\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Inside a loop which iterates over the range of n (number of training examples), find the optimal theta by \n",
    "calling trainLinearReg(..) using the first i examples (X_new[:i], y[:i]), then compute the corresponding \n",
    "training error err_train (using X_new[:i], y[:i]) and the validation error err_val (using Xval_new, yval) ...\n",
    "\"\"\"\n",
    "errs_train, errs_val = [], [] # Lists to save the training and validation errors\n",
    "for i in range(2, len(y)): # Start from 2 examples at least\n",
    "    pass\n",
    "    # TODO: find the optimal theta parameters using the i first training examples\n",
    "    # ...\n",
    "    \n",
    "    # TODO: compute the training error using the optimal theta and the i first training examples\n",
    "    # ...\n",
    "    \n",
    "    # TODO: compute the validation error using the optimal theta and the validation dataset\n",
    "    # ...\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Complete the code below to plot the learning curve\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# TODO: plot the \"number of training examples\" vs the training errors\n",
    "# ...\n",
    "\n",
    "# TODO: plot the \"number of training examples\" vs the validation errors\n",
    "# ...\n",
    "\n",
    "ax.set_xlabel(\"Number of training examples\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "ax.set_title(\"Linear regression learning curve\")\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "The problem with our linear model was that it was too simple for the data and resulted in underfitting (high bias). In this part of the exercise, you will address this problem by adding more features. For using polynomial regression, our hypothesis has the form:\n",
    "$$\n",
    "\\begin{align}\n",
    "h_\\theta(x) &= \\theta_0 + \\theta_1 * (\\text{waterLevel}) + \\theta_2 * (\\text{waterLevel})^2 + \\dots + \\theta_p * (\\text{waterLevel})^p \\\\\n",
    "&= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_p x_p\n",
    "\\end{align}\n",
    "$$\n",
    "Notice that by defining $x_1 = (\\text{waterLevel}), x_2 = (\\text{waterLevel})^2, \\dots, x_p = (\\text{waterLevel})^p$, we obtain a linear regression model where the features are the various powers of the original value (waterLevel). Note that you don't have to account for the zero'th power in this function.\n",
    "\n",
    "Now, you will add more features using the higher powers of the existing feature $x$ in the dataset. Your task in this part is to complete the following code so that the function `polyFeatures(..)` maps the original training set $X$ of size $n \\times 1$ into its higher powers. Specifically, when a training set $X$ of size $n \\times 1$ is passed into the function, the function should return a $n \\times p$ matrix `X_poly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO:\n",
    "Write the definition of the function polyFeatures(X, p) which takes \n",
    "as arguement the original training set X and the degree of the polynomial p. \n",
    "The function should return a new set X_poly of p features (i.e. matrix of len(X) rows and p columns).\n",
    "\"\"\"\n",
    "def polyFeatures(X, p):\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "\"\"\" TODO:\n",
    "You can call your polyFeatures(...) function here on some exampls to check if it works correctly.\n",
    "\"\"\"\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have completed the function `polyFeatures`, we will proceed to train polynomial regression using your linear regression cost function. Keep in mind that even though we have polynomial terms in our feature vector, we are still solving a linear regression optimization problem. The polynomial terms have simply turned into features that we can use for linear regression. We are using the same cost function and gradient that you wrote for the earlier part of this Lab.\n",
    "\n",
    "In the Python code below, we are using a polynomial of degree 8. The function `polyFeatures(..)` is therefore applied with $p=8$ to the training set `X`, the validation set `Xval` and the test set `Xtest`, to get the corresponding projected data `X_poly`, `Xval_poly` and `Xtest_poly`.\n",
    "\n",
    "It turns out that if we run the training directly on the projected data `X_poly`, it will not work well as the features would be badly scaled (e.g., an example with $x_1 = 40$ will have a feature $x_8 = 40^8$). Therefore, we need to use feature normalization. In the following Python code, we first normalize the features of the training set and add to it an additional first column of ones to get `X_poly_normalized`. The parameters used for normalization are stored in variables `mu` and `sigma`. Then, we train the linear regression model (i.e. find the optimal parameters vector $\\theta$) by calling the function `trainLinearReg(..)` using our new training set `X_poly_normalized`, `y`, an initial $\\theta$ vector of dimension $p+1$ (as we have $p$ features now), and a value of $\\lambda$ set to $0$ for now (no regularization). Then, we plot two figures which looks like follows. From the first figure, you should see that the polynomial fit is able to follow the data-points very well - thus, obtaining a low training error. However, the polynomial fit is very complex and even drops off at the extremes. This is an indicator that the polynomial regression model is overfitting the training data and will not generalize well. To better understand the problems with the unregularized ($\\lambda = 0$) model, you can see from the second figure that the learning curve shows the same effect where the training error is low, but the validation error is high. There is a gap between the training and cross validation errors, indicating a high variance problem.\n",
    "\n",
    "We have already implemented all this for you. You just need to read the code and then run it.\n",
    "\n",
    "<img src=\"imgs/Lab4APolyPlotLmd0.png\" width=\"600px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The regularization parameter lmd\n",
    "lmd = 0.0\n",
    "\n",
    "# Using polyFeatures(..) with p=8 to map the original data to a higher dimension\n",
    "p = 8\n",
    "X_poly = polyFeatures(X, p) # on the training set\n",
    "Xval_poly = polyFeatures(Xval, p) # on the validation set\n",
    "Xtest_poly = polyFeatures(Xtest, p) # on the test set\n",
    "\n",
    "# mean vector and standard deviation vector\n",
    "mu = np.mean(X_poly, axis=0)\n",
    "sigma = np.std(X_poly, axis=0)\n",
    "\n",
    "# normalizing the training set and validation set using mu and sigma and adding an aditional first column of ones\n",
    "X_poly_normalized = add_all_ones_column((X_poly - mu) / sigma)\n",
    "Xval_poly_normalized = add_all_ones_column((Xval_poly - mu) / sigma)\n",
    "\n",
    "# Training to find the optimal parameters vector theta\n",
    "theta_init = np.zeros(p+1) # we p features, so we need p+1 parameters (as we have theta_0)\n",
    "theta = trainLinearReg(X_poly_normalized, y, theta_init, lmd)\n",
    "\n",
    "# Plotting the dataset and the polynomial regression curve\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.set_xlabel(\"Change in water level (x)\")\n",
    "ax1.set_ylabel(\"Water flowing out of the dam (y)\")\n",
    "ax1.set_title(r\"Polynomial Regression Fit ($\\lambda = {}$)\".format(lmd))\n",
    "\n",
    "ax2.set_xlabel(\"Number of training examples\")\n",
    "ax2.set_ylabel(\"Error\")\n",
    "ax2.set_title(r\"Polynomial Regression Learning Curve ($\\lambda = {}$)\".format(lmd))\n",
    "\n",
    "x_plot = np.linspace(-60, 40, 100)\n",
    "x_plot_poly = polyFeatures(x_plot.reshape(len(x_plot), 1), p)\n",
    "x_plot_poly_normalized = add_all_ones_column((x_plot_poly - mu) / sigma)\n",
    "y_plot = x_plot_poly_normalized @ theta\n",
    "ax1.plot(x_plot, y_plot, linestyle=\"--\", color=\"green\", label=\"Polynomial fit\")\n",
    "ax1.scatter(X[:, 0], y, marker=\"x\", color=\"red\", label = \"Training examples\")\n",
    "\n",
    "# Plotting the learning curves using the training and validation sets\n",
    "errs_train, errs_val = [], []\n",
    "for i in range(2, len(y)):\n",
    "    theta = trainLinearReg(X_poly_normalized[:i], y[:i], theta_init, lmd)\n",
    "    errs_train.append( E(theta, X_poly_normalized[:i], y[:i], 0) )\n",
    "    errs_val.append( E(theta, Xval_poly_normalized, yval, 0) )\n",
    "    \n",
    "ax2.plot(range(2, len(y)), errs_train, label=\"Training error\")\n",
    "ax2.plot(range(2, len(y)), errs_val, label=\"Validation error\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the regularization parameter $\\lambda$\n",
    "In this section, you will get to observe how the regularization parameter affects the bias-variance of regularized polynomial regression. You should now modify the $\\lambda$ parameter (i.e. variable `lmd`) in previous code and try $\\lambda = 1$ and $\\lambda = 50$ (you could also try with other values of $\\lambda$). For each of these values, the above code should generate two figures (the polynomial fit to the data and the learning curve).\n",
    "\n",
    "For $\\lambda = 1$, you should see a polynomial fit that follows the data trend well and a learning curve showing that both the validation and training error converge to a relatively low value. This shows the $\\lambda = 1$ regularized polynomial regression model does not have the high-bias or high-variance problems. In fact, it achieves a good trade-off between bias and variance. For $\\lambda = 50$, you should see a polynomial fit that does not follow the data well. In this case, there is too much regularization and the model is unable to fit the training data.\n",
    "\n",
    "## Selecting $\\lambda$ using the validation set\n",
    "From the previous section, you observed that the value of $\\lambda$ can significantly affect the results of regularized polynomial regression on the training and cross validation set. In particular, a model without regularization ($\\lambda = 0$) fits the training set well, but does not generalize. Conversely, a model with too much regularization (e.g. $\\lambda = 50$) does not fit the data well. A good choice of $\\lambda$ (e.g., $\\lambda = 1$ for this dataset) can provide a good fit to the data.\n",
    "\n",
    "In this section, you will implement an automated method to select the $\\lambda$ parameter. Concretely, you will use a cross validation set to evaluate how good each $\\lambda$ value is. After selecting the best $\\lambda$ value using the validation set, we can then evaluate the model on the test set to estimate how well the model will perform on actual unseen data.\n",
    "\n",
    "Your task is to complete the code below. Specifically, you should use the `trainLinearReg(..)` function to train the model using different values of $\\lambda$ and compute the training error and validation error. You should try $\\lambda$ in the following range: `[0, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]`. You should also plot a curve that shows the validation error and training error with respect to the different values of $\\lambda$. You should see a plot similar to the following figure, which allows you to select which $\\lambda$ parameter to use. In this figure, we can see that the best value of $\\lambda$ is around $3$ (as it gives the smallest validation error).\n",
    "\n",
    "<img src=\"imgs/Lab4AerrVSlambda.png\" width=\"400px\" />\n",
    "\n",
    "*Note:* Due to randomness in the training and validation splits of the dataset, the cross validation error can sometimes be lower than the training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmd_range = [0, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "errs_train, errs_val = [], []\n",
    "\n",
    "\"\"\" TODO:\n",
    "For each value of lmd you should call trainLinearReg(..) to train a model using the training set \n",
    "X_poly_normalized, y, then compute the training error (on the training set: X_poly_normalized, y) \n",
    "and the validation error (on the validation set: Xval_poly_normalized, yval).\n",
    "\"\"\"\n",
    "for lmd in lmd_range:\n",
    "    pass\n",
    "    # TODO ...\n",
    "    # TODO ...\n",
    "    # TODO ...\n",
    "\n",
    "\n",
    "\"\"\" TODO:\n",
    "Plot a curve that shows the validation error and training error with respect to lambda\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot of the training errors vs lambda values\n",
    "# ...\n",
    "# Plot of the validation errors vs lambda values\n",
    "# ...\n",
    "\n",
    "ax.set_xlabel(\"lambda\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "ax.legend()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing test set error\n",
    "In the previous section, you implemented code to compute the validation error for various values of the regularization parameter $\\theta$. However, to get a better indication of the model's performance in the real world, it is important to evaluate the \"*final*\" model on a test set that was not used in any part of training (that is, it was neither used to select the regularization parameter $\\lambda$, nor to learn the model parameters $\\theta$).\n",
    "\n",
    "In the code below, you should compute the test error using the best value of $\\theta$ you found (using $\\lambda = 3$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO:\n",
    "Find the best parameters vector theta by training the polynomial regression \n",
    "model using lambda = 3. Then compute the error on the test set.\n",
    "Note: don't forget to normalize the test set before.\n",
    "\"\"\"\n",
    "# ...\n",
    "# ...\n",
    "# ...\n",
    "# err_test = ...\n",
    "# print(\"err_test =\", err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (OPTIONAL) Performing a 10-fold-cross-validation\n",
    "\n",
    "This section is optional.\n",
    "\n",
    "Combine the training and validation sets into one set `Xall`, `yall`. Note: in Python you can combine two datasets A and B (two numpy arrays) into one dataset using `AB = np.append(A, B, axis=0)`.\n",
    "\n",
    "Implement 10-fold-cross-validation to evaluate to find the best value for the hyperparameter $\\lambda$. This will be the value that gives you the best generalization error.\n",
    "\n",
    "Finally, use this best value of $\\lambda$ to train a model on the whole dataset `Xall`, `yall`, and then test this model on the test dataset `Xtest`, `ytest` and compute the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Plot the learning curves based on randomly selected examples as described above.\n",
    "\"\"\"\n",
    "# Combine X with Xval\n",
    "# Combine y with yval\n",
    "# Perform a 10-fold-cross-validation to find the best value for the hyperparameter lambda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
